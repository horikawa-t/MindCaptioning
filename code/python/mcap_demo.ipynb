{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e50001a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename: mcap_demo.ipynb\n",
    "# source activate mcap_demo\n",
    "\n",
    "# set path to MindCaptioning directory\n",
    "rootPath = './'\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import time\n",
    "\n",
    "# add path to code\n",
    "sys.path.append(rootPath+'code/python/util/')\n",
    "from thutil4 import getFN, getDN, setdir, fix_seed,randsample\n",
    "import mcap_utils_demo as mu\n",
    "\n",
    "gpu_use = 1\n",
    "if gpu_use:\n",
    "    gpu_id = '0'\n",
    "    print('Start script: gpu device:%s' %(gpu_id))\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = gpu_id\n",
    "else:\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = \"\"\n",
    "device = \"cuda\" if torch.cuda.is_available() and gpu_use == 1 else \"cpu\"\n",
    "print('gpu availability:%d'%(torch.cuda.is_available()))\n",
    "\n",
    "savdir_general    = rootPath + 'res/text_generation/'\n",
    "decfeat_dir       = rootPath + 'res/decoding/'\n",
    "LMmodeldir        = rootPath + 'data/model/'\n",
    "normparam_dat_dir = rootPath + 'data/feature/norm_param/'\n",
    "capdata_dir       = rootPath + 'data/caption/'\n",
    "\n",
    "# set proxy if necessary\n",
    "proxies = {\n",
    "    \"http\": \"\",\n",
    "    \"https\": \"\",\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d8c424",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "968d9567",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b91d271d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model, normalization, caption_data and parameter preparations\n",
    "\n",
    "# setting model\n",
    "# select MLM from ['bert-base-cased','bert-base-uncased','bert-large-cased','bert-large-uncased','bert-large-uncased-whole-word-masking','bert-large-cased-whole-word-masking','roberta-base','roberta-large','deberta-large-feedback']\n",
    "# you can test untrained model by addiing \"_untrained\" (e.g., 'roberta-large_untrained')\n",
    "MLMType = 'roberta-large' \n",
    "\n",
    "# select LM for feature extraction from ['bert-base-uncased','bert-large-uncased','bert-base-cased','bert-large-cased','bert-large-uncased-whole-word-masking','bert-large-cased-whole-word-masking','openai-gpt','gpt2','gpt2-medium','gpt2-large','gpt2-xl','xlnet-base-cased','xlnet-large-cased','roberta-base','roberta-large','distilbert-base-uncased','distilbert-base-cased','distilgpt2','albert-base-v1','albert-large-v1','albert-xlarge-v1','albert-xxlarge-v1','albert-base-v2','albert-large-v2','albert-xlarge-v2','albert-xxlarge-v2','t5-small','t5-base','t5-large','bart-base','bart-large','ctrl','xlm-mlm-17-1280','xlm-mlm-100-1280','electra','xlm-roberta-base','xlm-roberta-large','clip_l','sgpt','deberta-base','deberta-large','deberta-xlarge']\n",
    "LMType = 'deberta-large'\n",
    "\n",
    "# initialize\n",
    "start = time.time()\n",
    "\n",
    "# load pre-trained masked language model\n",
    "tokenizer, model = mu.load_mlm_model(LMmodeldir, MLMType, proxies, device)\n",
    "# load feature computation model\n",
    "tokenizer_lm, model_lm, nlayers = mu.load_lm_model(LMmodeldir, LMType, proxies, device)\n",
    "# set evaluation mode\n",
    "model.eval(),model_lm.eval()\n",
    "\n",
    "# prepre skip tokens, if any\n",
    "skip_token_ids_mlm = mu.set_skip_token_ids(tokenizer, speficied_skip_tokens=[], include_special_token=True)\n",
    "skip_token_ids_lm = mu.set_skip_token_ids(tokenizer_lm, speficied_skip_tokens=[], include_special_token=True)\n",
    "\n",
    "# set parameters\n",
    "params = {\n",
    "    'nItr': 100,\n",
    "    'metricType': 'corr',\n",
    "    'do_norm': 1,\n",
    "    'beamwidth': 5,\n",
    "    'nMaskCands': 5,\n",
    "    'nMaskPerSentence': 2,\n",
    "    'nGram4Mask': 3,\n",
    "    'multiMaskType':'forward_seq',\n",
    "    'maskingUnitType':'token',\n",
    "    'add_insert_mask': 1,\n",
    "    'mLayerType': 'vstack',\n",
    "    'optimal_th': 0.001,\n",
    "    'topk': 5,\n",
    "    'max_batch_samp': 200,\n",
    "    'length_penalty_type':'token',\n",
    "    'length_penalty_w': 0.10,\n",
    "    'mlmscoreType': 'modified',\n",
    "    'mlm_sampling_type': 'sampling',\n",
    "    'mlms_fix_weight': 0,\n",
    "    'nMax_MLMs_cands':5000,\n",
    "    'do_reflesh': 1,\n",
    "    'reflesh_th': [10,0.1,5,0.00],\n",
    "    'add_mask_removal': False,\n",
    "    'layerIdx': range(0,nlayers),\n",
    "    'device':device,\n",
    "}\n",
    "\n",
    "# load normalization parameters\n",
    "normparam_path = f\"{normparam_dat_dir}/{LMType}/\"\n",
    "feat_mu_all, feat_sd_all = mu.prepare_norm_params(normparam_path, nlayers, device=device)\n",
    "\n",
    "# load caption data\n",
    "caps_data = mu.load_caption_data(capdata_dir, ['ck20'])\n",
    "nCapEach = 20\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c61b22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce31b719",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text generation from an arbitrary word sequence\n",
    "# You can test arbitrary word sequences to examine the effectiveness of our method\n",
    "target_sentence = 'Five apples are on the table.'\n",
    "target_sentence = 'In the beginning God created the heavens and the earth.'\n",
    "target_sentence = 'Imagination is more important than knowledge.'\n",
    "target_sentence = 'To be, or not to be, that is the question.'\n",
    "target_sentence = 'May the Force be with you.'\n",
    "\n",
    "# extract semantic features\n",
    "feat_target = mu.compute_sentence_feature_patterns_wrapper([target_sentence], model_lm, tokenizer_lm, skip_token_ids=skip_token_ids_lm, do_norm=params['do_norm'], feat_mu_all=feat_mu_all, feat_sd_all=feat_sd_all, device=device, layerIdx=params['layerIdx'], max_batch_samp=params['max_batch_samp'])[0][0]\n",
    "\n",
    "# Start optimization\n",
    "best_cands, scores_all, scores_eval_all = mu.text_optimization_steps(feat_target, feat_mu_all, feat_sd_all, model, tokenizer, skip_token_ids_mlm, model_lm, tokenizer_lm, skip_token_ids_lm, params, device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e687b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text generation from brain-decoded features\n",
    "# if you have finished creating/downloading decoded features, you can use brain-decoded features for text generation\n",
    "\n",
    "# parameters [CHANGE here]\n",
    "dataType = 'testPerception' # ['testPerception','testImagery','trainPerception']\n",
    "sbj = 'S1'\n",
    "roiType = 'WB'\n",
    "decfeat_path = f\"{decfeat_dir}/{dataType}/{LMType}/{sbj}/{roiType}/\"\n",
    "decsampidx = 6 # [0-71 for 'testPerception' and 'testImagery'; 0-2107 for 'trainPerception']\n",
    "\n",
    "# extract semantic features\n",
    "videoidx = mu.prepare_label_parameters(decsampidx, decfeat_path, device)[0]\n",
    "\n",
    "feat_target = mu.prepare_feature_data(decsampidx, decfeat_path, params)[0]\n",
    "\n",
    "print(f\"VideoID:{videoidx+1}\\nCorrect reference:\") # this ID corresponds to video file names from Cowen & Keltner (2017)\n",
    "for i,cap in enumerate(caps_data[videoidx*nCapEach:((videoidx+1)*nCapEach)]): \n",
    "    print(f\"[{i+1}]:{cap}\")\n",
    "\n",
    "# Start optimization\n",
    "print('\\nGeneratd description:')\n",
    "best_cands, scores_all, scores_eval_all = mu.text_optimization_steps(feat_target, feat_mu_all, feat_sd_all, model, tokenizer, skip_token_ids_mlm, model_lm, tokenizer_lm, skip_token_ids_lm, params, device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db11cab8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce297fa",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6113b7c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed8f0af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b8a5b8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a211aa66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf4e894",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a04ab8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2343e00e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e2fde6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c90ae76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860b48cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e2c685e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f769e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45027faa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec03c2bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
